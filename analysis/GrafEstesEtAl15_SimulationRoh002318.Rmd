---
title: "Simulation_GrafEstesLew-Williams15"
output:
  pdf_document: default
  html_document:
    df_print: paged
  html_notebook:
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "/Users/rohrlich/go/src/github.com/ccnlab/lang-acq/data/GrafEstes/")
```
#### Load Libraries
```{r}
library(Matrix)
library(lme4)
library(emmeans)
library(ggplot2)
library(dplyr)
library(psych)
```
### Terminology
In-Word - the transition between syllables within a word - 100% predictable for the data in this simulation

Next-Word - the transition between syllables within a word - 50% predictable for the data in this simulation

### Factors
run - equivalent to a subject as each run starts with a different random seed - treated as a random effect

phase - pretrain/test or train/test

epoch - each epoch we average the values from the trial data

layer - brain layer

condition - whether the syllable transition is "in-word" or "to next-word"

cosine - the cosine value for the run/epoch/condition (the independent variable)

## ---------------------------------------------
## Pretrained Network - Visualization

### Import data and name columns
### Pretraining Test Data
```{r}
grafestes2318Pretrain.df <- read.table("roh002318/WordSeg_0-24_preTstEpcTidy.tsv", header=FALSE, sep="\t")
grafestes2318Pretrain.df <- setNames(grafestes2318Pretrain.df, c("run","phase","epoch","layer","condition", "cosine"))
```
### Training Test Data
```{r}
grafestes2318PostPretrain.df <- read.table("roh002318/WordSeg_0-24_tstEpcTidy.tsv", header=FALSE, sep="\t")
grafestes2318PostPretrain.df <- setNames(grafestes2318PostPretrain.df, c("run","phase","epoch","layer","condition", "cosine"))
```
### Pretraining followed by Training Test Data 
```{r}
grafestes2318PreAndPosttrain.df <- read.table("roh002318/WordSeg_0-24_prePostTstEpcTidy.tsv", header=FALSE, sep="\t")
grafestes2318PreAndPosttrain.df <- setNames(grafestes2318PreAndPosttrain.df, c("run","phase","epoch","layer","condition", "cosine"))
```

### Pretraining Boxplot condition X epoch
```{r}
v1 = c(1.5, 3.5, 5.5, 7.5, 9.5)
v2 = c("10",  "20", "30", "40", "50")
boxplot(cosine ~ condition*epoch, data=grafestes2318Pretrain.df,
        xlab = "Epoch",
        ylab = "Cosine Similarity",
        ylim = range(0.0:1.0),
        col = c("#3399ff", "#ff3333"), # websafe
        xaxt = "n"
        )
legend("bottomright", legend = c("In-Word", "Next-Word"),
       col = c("#3399ff", "#ff3333"), # websafe
       pch=15, bty="n", pt.cex=2, horiz=F, inset=c(0.0, .80)
       )
axis(side=1, at = v1, labels=v2)
```
## ---------------------------------------------
### Training (after pre) Boxplot condition X epoch
```{r}
v1 = c(1.5, 3.5, 5.5, 7.5, 9.5, 11.5, 13.5, 15.5, 17.5, 19.5)
    v2 = c("1",  "2", "3", "4", "5", "6", "7", "8", "9", "10")
    boxplot(cosine ~ condition*epoch, data=grafestes2318PostPretrain.df,
        xlab = "Epoch",
        ylab = "Cosine Similarity",
        ylim = range(0.0:1.0),
        col = c("#3399ff", "#ff3333"), # websafe
        xaxt="n"
        )
legend("bottomright", legend = c("In-Word", "Next-Word"),
       col = c("#3399ff", "#ff3333"), # websafe
       pch=15, bty="n", pt.cex=2, horiz=F, inset=c(0.0, 0.0)
       )
abline(v=12.5, col="black", lty=2)
arrows(x0=14.5, y0=.8, x1=12.7, y1=.8, length=0.1)
text(x=14.7, y=.8, labels="End of infant training", pos=4)
axis(side=1, at = v1, labels=v2)
```
## ---------------------------------------------
### Pretraining and Training Boxplot condition X epoch
```{r}
v1 = c(1.5, 3.5, 5.5, 7.5, 9.5, 11.5, 13.5, 15.5, 17.5, 19.5, 21.5, 23.5, 25.5, 27.5, 29.5)
    v2 = c("10",  "20", "30", "40", "50", "1",  "2", "3", "4", "5", "6", "7", "8", "9", "10")
    boxplot(cosine ~ condition*epoch, data=grafestes2318PreAndPosttrain.df,
        xlab = "Epoch",
        ylab = "Cosine Similarity",
        ylim = range(0.0:1.0),
        col = c("#3399ff", "#ff3333"), # websafe
        xaxt="n"
        )
legend("bottomright", legend = c("In-Word", "Next-Word"),
       col = c("#3399ff", "#ff3333"), # websafe
       pch=15, bty="n", pt.cex=2, horiz=F, inset=c(0.0, 0.0)
       )
abline(v=10.5, col="black", lty=1)
text(x=5, y=.9, labels="pretraining", pos=1)
abline(v=22.5, col="black", lty=2)
arrows(x0=24.5, y0=.8, x1=22.7, y1=.8, length=0.1)
text(x=24.7, y=.8, labels="     end of\ninfant training", pos=4)
axis(side=1, at = v1, labels=v2, cex.axis=1.0)
```
### Boxplot condition X layer
```{r}
v1 = c(1.5, 3.5, 5.5, 7.5, 9.5)
v2 = c("CB", "CPB", "RB", "RPB", "STS")
boxplot(cosine ~ condition*layer, data=grafestes2318PostPretrain.df,
        xlab = "Layer",
        ylab = "Cosine Similarity",
        ylim = range(0.0:1.0),
        col = c("#3399ff", "#ff3333"), # websafe
        xaxt = "n"
        )
legend("bottomright", legend = c("In-Word", "Next-Word"),
      col = c("#3399ff", "#ff3333"), # websafe
       pch=15, bty="n", pt.cex=2, horiz=F, inset=c(0.0, 0.0))
axis(side=1, at = v1, labels=v2)
```
## Pretrained Network - Mixed Model Analysis
### Full Model with within factors epoch, layer, condition
```{r}
grafestesPretrained.model_simple = lmer(cosine ~ epoch + layer + condition + (1|run), data=grafestes2318PostPretrain.df, REML=FALSE)
summary(grafestesPretrained.model_simple)
```

### Reduced model - no condition factor
```{r}
grafestesPretrained.model_nocondition = lmer(cosine ~ epoch + layer + (1|run), data=grafestes2318PostPretrain.df, REML=FALSE)
summary(grafestesPretrained.model_nocondition)
```
### Likelihood Ratio Test - full vs no condition factor (i.e. in-word vs next-word)
```{r}
anova(grafestesPretrained.model_simple, grafestesPretrained.model_nocondition)
```
### Reduced Model - no epoch factor
```{r}
grafestesPretrained.model_noepoch = lmer(cosine ~ condition + layer + (1|run), data=grafestes2318PostPretrain.df, REML=FALSE)
summary(grafestesPretrained.model_noepoch)
```
### Likelihood Ratio Test - full vs no epoch factor
```{r}
anova(grafestesPretrained.model_simple, grafestesPretrained.model_noepoch)
```
### Reduced Model - no layer factor
```{r}
grafestesPretrained.model_nolayer = lmer(cosine ~ condition + epoch + (1|run), data=grafestes2318PostPretrain.df, REML=FALSE)
summary(grafestesPretrained.model_nolayer)
```
### Likelihood Ratio Test - full vs no layer factor
```{r}
anova(grafestesPretrained.model_simple, grafestesPretrained.model_nolayer)
```
## Pretrained Network - Interactions
### Full Model with condition x layer interaction
```{r}
grafestesPretrained.model_interaction = lmer(cosine ~ epoch + layer * condition + (1|run), data=grafestes2318PostPretrain.df, REML=FALSE)
summary(grafestesPretrained.model_interaction)
```
### Likelihood Ratio Test - full additive vs full interaction
```{r}
anova(grafestesPretrained.model_simple, grafestesPretrained.model_interaction)
```
### Visualizing the Interaction (ggplot)
```{r}

p <- emmip(grafestesPretrained.model_interaction,  condition ~ layer)
p + theme(
  panel.background = element_rect(fill = "white"),
  text = element_text(size = 14),
  axis.line = element_line(color = "black"),
  legend.position = c(.20, .85),
  legend.key = element_rect(fill = "white")
) +
  ylim(0.35, 0.60) +
  xlab("Layer") +
  ylab("Cosine Similarity") +
  scale_color_manual(values = c("#3399ff", "#ff3333"))
p
```
### Exploring the 2 axes of Auditory Cortex
```{r}
emm = emmeans(grafestesPretrained.model_interaction, specs = ~ layer | condition)
summary(emm)

CB = c(1, 0, 0, 0, 0)
CPB = c(0, 1, 0, 0, 0)
RB = c(0, 0, 1, 0, 0)
RPB = c(0, 0, 0, 1, 0)
STS = c(0, 0, 0, 0, 1)

contrast(emm, method = list("STS - CPB" = STS - CPB,
                            "STS - RPB" = STS - RPB,
                            "CPB - CB" = CPB - CB,
                            "RPB - RB" = RPB - RB,
                            "RPB - CPB" = RPB - CPB,
                            "RB - CB" = RB - CB))
```
## --------------------------------------------
## Pretraining Data Only  - Mixed Model Analysis
### Full Model with within factors epoch, layer, condition
```{r}
grafestesPre.model_simple = lmer(cosine ~ epoch + layer + condition + (1|run), data=grafestes2318Pretrain.df, REML=FALSE)
summary(grafestesPre.model_simple)
```
### Reduced Model - no condition factor
```{r}
grafestesPre.model_nocondition = lmer(cosine ~ epoch + layer + (1|run), data=grafestes2318Pretrain.df, REML=FALSE)
summary(grafestesPre.model_nocondition)
```
### Pretrain - Likelihood Ratio Test - full vs no condition factor (i.e. in-word vs next-word)
```{r}
anova(grafestesPre.model_simple, grafestesPre.model_nocondition)
```
### Reduced Model - no epoch factor
```{r}
grafestesPre.model_noepoch = lmer(cosine ~ condition + layer + (1|run), data=grafestes2318Pretrain.df, REML=FALSE)
summary(grafestesPre.model_noepoch)
```
### Pretrain - Likelihood Ratio Test - full vs no epoch factor
```{r}
anova(grafestesPre.model_simple, grafestesPre.model_noepoch)
```
## Original GrafEstes Experiment 1 Compared with Simulation
### Subset of Simulation Data: Epoch 6 Only (comparable training point)
```{r}
epoch6.df <- select(filter(grafestes2318PostPretrain.df, epoch == 105),c(1:6))
epoch6stats <- aggregate(epoch6.df$cosine, by = list(cond = epoch6.df$condition), FUN = function(x) c(mean = mean(x), sd = sd(x), n = length(x)))
epoch6stats <- do.call(data.frame, epoch6stats)
epoch6stats$se <- epoch6stats$x.sd / sqrt(epoch6stats$x.n) # std error
# View(epoch6stats)
```
### Epoch 6 Data Only - full additive model
```{r}
grafestesPretrainedEpoch6.model_simple = lmer(cosine ~ layer + condition + (1|run), data=epoch6.df, REML=FALSE)
summary(grafestesPretrainedEpoch6.model_simple)
```
### Epoch 6 Data Only - reduced model - no condition factor
```{r}
grafestesPretrainedEpoch6.model_nocondition = lmer(cosine ~ layer + (1|run), data=epoch6.df, REML=FALSE)
summary(grafestesPretrainedEpoch6.model_nocondition)
```
### Likelihood Ratio Test - Epoch 6 data only - simple vs reduced no condition
```{r}
anova(grafestesPretrainedEpoch6.model_simple, grafestesPretrainedEpoch6.model_nocondition)
```
### Experiment and Simulation Side by Side
```{r}
par(mfrow=c(1,2))

# GrafEstes Experiment 1 Data - Block 1 - averaged over 2 age groups
n = 40 # both age groups
time <- c(11.05, 9.66) # secs (block 1)
sd <- c(3.65, 3.16) # std dev
seww <- sd[1] / sqrt(n)  # calculated std err
sepw <- sd[2] / sqrt(n)
se <- c(seww, sepw) # calculated std err

barplot(time,
        ylim=c(0,14),
        col = c("#3399ff", "#ff3333"), # websafe
        names.arg = c("Whole-Word", "Part-Word"),
        ylab = "Mean Listening Time (sec)",
        xlab = "Infants Block 1"
)
wwbarctr = 0.70
pwbarctr = 1.90
len = .025
segments(wwbarctr, time[1] - se[1], wwbarctr, time[1] + se[1], lwd=2)
segments(wwbarctr - len, time[1] - se[1], wwbarctr + len, time[1] - se[1], lwd=2)
segments(wwbarctr - len, time[1] + se[1], wwbarctr + len, time[1] + se[1], lwd=2)
segments(pwbarctr, time[2]
         - se[2], pwbarctr, time[2] + se[2], lwd=2)
segments(pwbarctr - len, time[2] - se[2], pwbarctr + len, time[2] - se[2], lwd=2)
segments(pwbarctr - len, time[2] + se[2], pwbarctr + len, time[2] + se[2], lwd=2)

# Simulation
cs <- epoch6stats$x.mean
cosineSim <- c(epoch6stats$x.mean[1], epoch6stats$x.mean[2])
se <- c(epoch6stats$se[1], epoch6stats$se[2])
barplot(cosineSim,
        ylim=c(0,0.7),
        col = c("#3399ff", "#ff3333"), # websafe
        names.arg = c("In-Word\n(Whole-Word)", "Next-Word\n(Part-Word)"),
        ylab = "Cosine Similarity",
        xlab = "Simulation"
)
wwSimbarctr = 0.70
pwSimbarctr = 1.90
len = .025
segments(wwSimbarctr, cosineSim[1] - se[1], wwSimbarctr, cosineSim[1] + se[1], lwd=2)
segments(wwSimbarctr - len, cosineSim[1] - se[1], wwSimbarctr + len, cosineSim[1] - se[1], lwd=2)
segments(wwSimbarctr - len, cosineSim[1] + se[1], wwSimbarctr + len, cosineSim[1] + se[1], lwd=2)
segments(pwSimbarctr, cosineSim[2] - se[2], pwSimbarctr, cosineSim[2] + se[2], lwd=2)
segments(pwSimbarctr - len, cosineSim[2] - se[2], pwSimbarctr + len, cosineSim[2] - se[2], lwd=2)
segments(pwSimbarctr - len, cosineSim[2] + se[2], pwSimbarctr + len, cosineSim[2] + se[2], lwd=2)
```
